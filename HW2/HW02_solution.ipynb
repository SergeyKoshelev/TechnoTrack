{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ №2 - обучение модели трехслойного перцептрона методом градиентного спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теоретическое задание\n",
    "**Вывод функции ошибки для задачи регрессии в предположении, что целевая переменная подчиняется распределению Лапласа**  \n",
    "Дан набор данных:\n",
    "$$\n",
    "\\{x_i, t_i\\}_{i=1}^N\n",
    "$$\n",
    "Модель регресии:\n",
    "$$\n",
    "y=\\theta^T\\phi(x)\n",
    "$$\n",
    "Воспользуемся вероятностным определением функции ошибки и методом максимального правдоподобия(Maximum Likelihood). Распределение Лапласа является экспоненциальным, поэтому удобнее сразу перейти к логарифмической фукнции правдоподобия\n",
    "$$\n",
    "t|x \\sim Laplace(\\theta^T\\phi(x), \\beta) \n",
    "$$\n",
    "<img src=\"files/mae.jpg\">\n",
    "Как видно, для целевой переменной, распределенной по Лапласу, функцией ошибки является MAE (mean absolute error).\n",
    "\n",
    "**В том же предположении относительно распределения целевой переменной вывод формы функции потерь с условием лапласовского априорного распределения параметров модели**  \n",
    "Максимальная апостериорная вероятность (MAP) считается, пользуясь байесовским выводом, с учетом априорной вероятности распределения параметров $\\theta$.\n",
    "$$\n",
    "P(\\theta|X)=\\frac{P(X|\\theta)P(\\theta)}{P(X)}\n",
    "$$\n",
    "Применяем ML метод. Первый множитель числителя уже был посчитан ранее, а множитель в знаменателе переходит в константу. Остается найти чем равен второй множитель числителя. Так как $\\theta$ тоже подчиняются распределению лапласа, то:\n",
    "<img src=\"files/aposterior.jpg\">\n",
    "Окончательно выбирая среднее значение $\\theta: m=0$ получаем:\n",
    "<img src=\"files/l1.jpg\">\n",
    "Таким образом, получилась функция ошибки MAE с L1 регуляризацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Текстовое описание\n",
    "Целью обучения модели является классификация изображений датасета **MNIST**. Датасет представляет собой набор рукописных цифр с фиксированным размером изображения 28х28, предварительно разделенный на тренировочную (**x_train, y_train**) и тестовую выборки (**x_test, y_test**). Задача модели - определить цифру, соответствующую произвольному изображению из тестового набора данных\n",
    "\n",
    "Каждое изображение состоит из 28х28=784 пикселей, где каждому пикселю соотвествует значение от 0 до 255 (0 - черный, 255 - белый). В качестве признакового описания одного изображения будет использоваться строка из 784 цифр от 0 до 1, полученная приведением исходной матрицы к строке и нормированием. Целевая переменная - значение от 0 до 9, соотвествующее правильной цифре на изображении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Трехслойный перцептрон\n",
    "Трехслойный перцептрон (один скрытый слой) - один из самых простых видов нейронных сетей, который можно представить формулой\n",
    "$$\n",
    "F(x) = \\Psi\\left(\\phi\\left( {x}\\cdot\\theta_1 + b_1 \\right)\\cdot\\theta_2 + b_2\\right),\n",
    "$$\n",
    "А также наглядным изображением вида\n",
    "<img src=\"files/perceptron.jpg\">\n",
    "Рассмотрим подробнее эту модель и её работу на одной входной строке данных (в нашем случае - строка, соответсвующая одному изображению).\n",
    "\n",
    "Первый (**входной слой**) - это наша исходная строка, состоящая из $N_1$ чисел. С помощью первой матрицы параметров $\\theta_1$ и вектора $b_1$ строка преобразуется к строке, как правило, другого размера $N_2$. Эта новая получившаяся строка представляет собой уже второй (**скрытый**) слой перцептрона.\n",
    "С помощью функции активации $\\phi$ (поточечная функция для строки данных) мы избавляемся от обычной линейной модели. Результат функции активации - выход скрытого слоя.  \n",
    "Далее аналогично переходу от входного к скрытому слою, с помощью матрицы параметров $\\theta_2$ и вектора $b_2$ попадаем на третий (**выходной слой**). Снова применяем функцию активации, на этот раз $\\Psi$ и получаем окончательное значение $F(x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ошибки\n",
    "Наша задача представляет собой задачу многоклассовой классификации с количеством классов: 10. Для такого рода задач применяется функция ошибки мультиномиальная кросс-энтропия(**multinomial cross entropy**).\n",
    "\n",
    "Для начала разберемся, как выглядит представление целевой переменной и результат работы перцептрона. Для подсчета функции ошибки и классификации изображения используется **one-hot encoding**: каждому изображению соотвествует строка из 10 чисел, каждое из которых определяет вероятность изображения быть той или иной цифрой (в коде будут представлены примеры).\n",
    "\n",
    "Тогда функция ошибки записывается в виде\n",
    "$$\n",
    "{\\mathscr{L}}\\left(\\hat{y},y\\right) = -\\sum_{j=1}^{K}{y_j*ln\\left(\\hat{y}_j\\right)},\n",
    "$$\n",
    "где $\\hat{y}=F(x)$, а $y$ - целевая переменная.  \n",
    "Так как все кроме одного (соответсвующего правильному значению) $y_j$ равны 0, а один из них равен 1, то функция ошибки записывается в более простом виде:\n",
    "$$\n",
    "{\\mathscr{L}}\\left(\\hat{y},y\\right) = -ln\\left(\\hat{y}_y\\right)\n",
    "$$\n",
    "## Мера качества модели\n",
    "Функция ошибки может дать лишь какое-то число, по которому невозможно оценить качество модели. Так как основной задачей перцептрона является правильная классификация цифры на картинке, то было бы более наглядно оценивать эффективность, используя число правильно и неправильно предсказанных результатов.\n",
    "\n",
    "Для этого используются метрики качества, например **accuracy score**\n",
    "$$\n",
    "Accuracy=\\frac{TP+TN}{TP+TN+FP+FN}\n",
    "$$\n",
    "Accuracy определяется только для одного конкретного класса **W**, по сути являясь долей правильных результатов. Для этого класса:  \n",
    "**TP(True Positive)** - количество верных исходов, результатом которых стал класс **W**  \n",
    "**TN(True Negative)** - количество верных исходов, результатом которых стал не класс **W**  \n",
    "**FP(False Positive)** - количество неверных исходов, результатом которых стал класс **W**  \n",
    "**FN(False Negative)** - количество неверных исходов, результатом которых не стал класс **W**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение\n",
    "### Исследование данных\n",
    "Для начала посмотрим несколько экземпляров датасета - изображения рукописных цифр.\n",
    "\n",
    "Далее рассмотрим распределение целевой переменной. Из него видно, что все 10 цифр распределены примерно одинаково, а значит можно применить стохастический градиентный спуск.\n",
    "\n",
    "Чтобы подготовить наши данные к обучению, во-первых, приведем данные к строчному виду, то есть заменим матрицу 28х28 одной строкой 1х784.  \n",
    "Модель выдает результат в виде one-hot, рассмотрим такое представление, однако, в коде использовать его не будем, так как можно обойтись и обычным представлением целевой переменной.  \n",
    "Из приведенных экземпляров датасета прослеживается, что некоторые пиксели (угловые и краевые) всегда черные. Поэтому проводим фильтрацию признаков, удаляя те, что имеют нулевую дисперсию (то есть принимают одно и то же значение).  \n",
    "В заключение стоит отметить, что для удобства вычислений, а также для избежания огромных чисел, будет полезно провести нормировку. В своем коде я нормирую признаки, приводя их к значению от 0 до 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load('./mnist.npz')\n",
    "x_train = mnist['x_train']\n",
    "y_train = mnist['y_train']\n",
    "# Обратите внимание на то, что целевая переменная в виде целых чисел от 0 до 9, в то время как в формулах,\n",
    "# приведенных выше, подразумевается one-hot кодирование целевой переменной\n",
    "x_test = mnist['x_test']\n",
    "y_test = mnist['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,5, figsize = (15,5)) \n",
    "for i in range(5) :\n",
    "    axes[i].imshow(x_train[i], cmap='gray')\n",
    "    axes[i].set_title('Number: {}'.format(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "sns.histplot(y_train)\n",
    "ax.set_title('Target, y', fontsize = 30)\n",
    "ax.set_xlabel('Value', fontsize = 30)\n",
    "ax.set_ylabel('Count', fontsize = 30)\n",
    "ax.set_xticks(np.arange(0, 10, step = 1))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before row reshape\n",
      "x_train.shape: (60000, 28, 28)\tx_test.shape: (10000, 28, 28)\n",
      "After row reshape\n",
      "x_train.shape: (60000, 784)\tx_test.shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print('Before row reshape')\n",
    "print('x_train.shape: {}\\tx_test.shape: {}'.format(x_train.shape, x_test.shape))\n",
    "train_count = x_train.shape[0]\n",
    "test_count = x_test.shape[0]\n",
    "\n",
    "x_train = x_train.reshape((train_count, 28*28))\n",
    "x_test = x_test.reshape((test_count, 28*28))\n",
    "print('After row reshape')\n",
    "print('x_train.shape: {}\\tx_test.shape: {}'.format(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of one-hot decoding\n",
      "5 : [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "0 : [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4 : [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "1 : [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "9 : [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('Examples of one-hot decoding')\n",
    "y_train_onehot = np.eye(10)[y_train]\n",
    "#y_test_onehot = np.eye(10)[y_test]\n",
    "for i in range(5):\n",
    "    print('{} : {}'.format(y_train[i], y_train_onehot[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67 useless features: \n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 52, 53, 54, 55, 56, 57, 82, 83, 84, 85, 111, 112, 140, 141, 168, 476, 560, 644, 645, 671, 672, 673, 699, 700, 701, 727, 728, 729, 730, 754, 755, 756, 757, 758, 759, 780, 781, 782, 783]\n",
      "Shapes after filtering features: \n",
      "Train:(60000, 717)\n",
      "Test:(10000, 717)\n"
     ]
    }
   ],
   "source": [
    "useless_features = []\n",
    "features_count = x_train.shape[1]\n",
    "for i in range(features_count):\n",
    "    if (x_train[:,i].std() == 0.0) :\n",
    "        useless_features.append(i)\n",
    "\n",
    "print('Found {} useless features: \\n{}'.format(len(useless_features), useless_features))\n",
    "\n",
    "x_train = np.delete(x_train, useless_features, axis=1)\n",
    "x_test = np.delete(x_test, useless_features, axis=1)\n",
    "print('Shapes after filtering features: \\nTrain:{}\\nTest:{}'.format(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization:\n",
      "x_train.min: 0\tx_train.max: 255\n",
      "Before normalization:\n",
      "x_train.min: 0.0\tx_train.max: 1.0\n"
     ]
    }
   ],
   "source": [
    "max_value = x_train.max()\n",
    "min_value = x_train.min()\n",
    "print('Before normalization:\\nx_train.min: {}\\tx_train.max: {}'.format(min_value, max_value))\n",
    "x_train = (x_train - min_value) / (max_value - min_value)\n",
    "x_test = (x_test - min_value) / (max_value - min_value)\n",
    "print('After normalization:\\nx_train.min: {}\\tx_train.max: {}'.format(x_train.min(), x_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "Класс **loss** отвечает за функцию потерь (cross-entropy) с используемыми методами backward и forward для вычисления градиента и значения функции ошибки.\n",
    "\n",
    "Класс **Linear** предназначен для линейной части. Для удобства вычислений внутри класса добавляется единичный столбец к данным, чтобы не считать отдельно градиент для вектора $b$.  \n",
    "Метод forward возвращает произведения входа на матрицу параметров $\\theta$, а метод backward возвращает производную по $\\theta$, если в качастве аргумента diff указано 'theta', или производную по $X$, если в качестве аргумента diff указано 'data'.\n",
    "\n",
    "Класс **Activation** отвечает за функцию активации $\\phi$ из формулы трехслойного перцептрона. Методы backward и forward возвращают соотвествующие градиент и активацию.\n",
    "\n",
    "Класс **Softmax** предназначен для последней активации $\\Psi$ выходного слоя. Методы backward и forward возвращают соотвествующие градиент и активацию.\n",
    "\n",
    "Класс **Perceptron** собирает всю модель трехслойного перцептрона вместе. Метод forward возвращает значение модели по входным данным. Метод backward не используется, так как градиенты по обеим матрицам параметров считаются отдельно в функции **backprop**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Differentiable:\n",
    "    def __init__(self):\n",
    "        self.state = None\n",
    "        pass\n",
    "    \n",
    "    def forward(self, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def backward(self, **kwargs):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss(Differentiable):\n",
    "    def __init__(self):\n",
    "        super(loss, self).__init__()\n",
    "    \n",
    "    def forward(self, **kwargs):\n",
    "        \n",
    "        loss_value = 0.0\n",
    "        y = kwargs['y']  #not one hot\n",
    "        y_pred = kwargs['y_pred']\n",
    "        dim = y.shape[0]\n",
    "        for i in range(dim) :\n",
    "            loss_value -= np.log(y_pred[i][y[i]])\n",
    "                \n",
    "        return loss_value\n",
    "    \n",
    "    \n",
    "    def backward(self, **kwargs):\n",
    "\n",
    "        y = kwargs['y']  #not one hot\n",
    "        y_pred = kwargs['y_pred']\n",
    "        dim = y.shape[0]\n",
    "        \n",
    "        partial_grad = np.zeros_like(y_pred)\n",
    "        \n",
    "        for i in range(dim) :\n",
    "            partial_grad[i][y[i]] = 1.0 / y_pred[i][y[i]]\n",
    "        \n",
    "        return partial_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Differentiable):\n",
    "    def __init__(self, output_dim):\n",
    "        super(Linear, self).__init__()\n",
    "        self.theta = None\n",
    "        self.output_dim = output_dim\n",
    "        self.X_ext = None\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.forward(X)\n",
    "    \n",
    "    def backward(self, **kwargs):\n",
    "        \n",
    "        if kwargs['diff'] == 'theta' :\n",
    "            partial_grad = self.X_ext\n",
    "        elif kwargs['diff'] == 'data' :\n",
    "            partial_grad = self.theta[1:,] #without bias\n",
    "        else :\n",
    "            raise ValueError\n",
    "            \n",
    "        return partial_grad\n",
    "    \n",
    "    def forward(self, X):\n",
    "        assert X.ndim == 2, \"X should be 2-dimensional: (N of objects, n of features)\"\n",
    "        \n",
    "        if (self.theta is None):\n",
    "            self.theta = np.zeros((X.shape[1] + 1, self.output_dim))\n",
    "        \n",
    "        X1 = np.c_[np.ones(len(X)), X]\n",
    "        self.X_ext = X1\n",
    "        \n",
    "        y_pred = np.dot(X1, self.theta)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Differentiable):\n",
    "    def __init__(self):\n",
    "        super(Activation, self).__init__()\n",
    "        self.data = None\n",
    "    \n",
    "    def __call__(self, **kwargs):\n",
    "        return self.forward(X=kwargs['X'])\n",
    "    \n",
    "    def backward(self, **kwargs):\n",
    "        \n",
    "        num = kwargs['num']\n",
    "        classes_count = self.data.shape[1]\n",
    "        partial_grad = np.zeros((classes_count, classes_count))\n",
    "        for i in range(classes_count) :\n",
    "            partial_grad[i][i] = int(self.data[num][i] > 0)\n",
    "                \n",
    "        return partial_grad\n",
    "    \n",
    "    def forward(self, **kwargs):\n",
    "        \n",
    "        y = kwargs['X']\n",
    "        y[y < 0] = 0\n",
    "        self.data = y\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Differentiable):\n",
    "    def __init__(self):\n",
    "        super(Softmax, self).__init__()\n",
    "        self.data = None\n",
    "    \n",
    "    def __call__(self, **kwargs):\n",
    "        return self.forward(X=kwargs['X'])\n",
    "    \n",
    "    def backward(self, **kwargs):\n",
    "        \n",
    "        num = kwargs['num']\n",
    "        classes_count = self.data.shape[1]\n",
    "        partial_grad = np.zeros((classes_count, classes_count))\n",
    "        for i in range(classes_count) :\n",
    "            for j in range (classes_count) :\n",
    "                delta = int(i == j)\n",
    "                partial_grad[i][j] = self.data[num][i] * (delta - self.data[num][j])\n",
    "        \n",
    "        return partial_grad\n",
    "    \n",
    "    def forward(self, **kwargs):\n",
    "       \n",
    "        X = kwargs['X']\n",
    "        dim = X.shape[0]\n",
    "        \n",
    "        for i in range(dim) :\n",
    "            X[i] -= np.max(X[i])\n",
    "            X[i] = np.exp(X[i])\n",
    "            X[i] /= sum(X[i])\n",
    "            \n",
    "        self.data = X #cache matrix of softmax values\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(Differentiable):\n",
    "    def __init__(self):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.softmax = None\n",
    "        self.linear1 = None\n",
    "        self.linear2 = None\n",
    "        self.relu = None\n",
    "    \n",
    "    def __call__(self, **kwargs):\n",
    "        return self.forward(X)\n",
    "    \n",
    "    def backward(self, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def forward(self, **kwargs):\n",
    "        \n",
    "        if self.linear1 == None :\n",
    "            self.linear1 = Linear(128)\n",
    "        if self.relu == None :\n",
    "            self.relu = Activation()\n",
    "        if self.linear2 == None :\n",
    "            self.linear2 = Linear(10)\n",
    "        if self.softmax == None:\n",
    "            self.softmax = Softmax()\n",
    "        \n",
    "        y1 = self.linear1(X=kwargs['X'])\n",
    "        h1 = self.relu(X=y1)\n",
    "        y2 = self.linear2(X=h1)\n",
    "        h2 = self.softmax(X=y2)\n",
    "        \n",
    "        return h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция **backprop** принимает на вход матрицы признаков, целевой переменной, модель, функцию ошибки, а также learning rate. В функции реализован алгоритм вычисления градиента **backpropogation**, предполагая что уже был выполнен прямой проход и во всех классах модели сохранены промежуточные значения.  \n",
    "На выходе возвращается модель с изменеными с помощью градиента матрицами параметров $\\theta_{1,2}$.\n",
    "\n",
    "Функция **accuracy_score** возвращает вектор мер **accuracy** для всех классов.\n",
    "\n",
    "Функция **train_loop** - цикл оптимизации параметров. На каждом шаге выполняется прямой проход по модели перцептрона, сохраняются значения функции ошибки и accuracy. После чего вызывается функция **backprop**, обновляющая коэффициенты модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(X, y, prediction, model, loss_fn, alpha = 1e-9) :\n",
    "    final_theta2_grad = np.zeros_like(model.linear2.theta)\n",
    "    final_theta1_grad = np.zeros_like(model.linear1.theta)\n",
    "    \n",
    "    batch_size = X.shape[0]   \n",
    "    for i in range(batch_size) :\n",
    "        \n",
    "        CE_SM_grad = np.dot(loss_fn.backward(y=y, y_pred=prediction), model.softmax.backward(num=i))\n",
    "    \n",
    "        linear2_grad_theta = model.linear2.backward(diff='theta')\n",
    "        theta2_grad = np.dot(linear2_grad_theta.transpose(), CE_SM_grad)\n",
    "        \n",
    "        linear1_grad_theta = model.linear1.backward(diff='theta')\n",
    "        theta1_grad = np.dot(linear1_grad_theta.transpose(), CE_SM_grad)\n",
    "        linear2_grad_data = model.linear2.backward(diff='data')\n",
    "        theta1_grad = np.dot(theta1_grad, linear2_grad_data.transpose())\n",
    "        relu_grad = model.relu.backward(num=i)\n",
    "        theta1_grad = np.dot(theta1_grad, relu_grad)\n",
    "        \n",
    "        final_theta2_grad +=theta2_grad\n",
    "        final_theta1_grad +=theta1_grad\n",
    "            \n",
    "    #print('{}, {}'.format(model.linear2.theta.shape, theta2_grad.shape))\n",
    "    #print('{}, {}'.format(model.linear1.theta.shape, theta1_grad.shape))        \n",
    "    model.linear2.theta += final_theta2_grad / batch_size * alpha\n",
    "    model.linear1.theta += final_theta1_grad / batch_size * alpha \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y, prediction_onehot):\n",
    "    classes_count = 10\n",
    "    prediction = np.zeros_like(y)\n",
    "    for i in range(y.shape[0]) :\n",
    "        prediction[i] = np.argmax(prediction_onehot[i])\n",
    "        \n",
    "    accuracies = []\n",
    "    classes_count = 10\n",
    "    for i in range(classes_count) :\n",
    "        y_i = (y == i) \n",
    "        prediction_i = (prediction == i)\n",
    "        accuracies.append(np.sum(y_i == prediction_i) / len(y_i))\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(X_full, y_full, model, loss_fn, epochs=100):\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    pbar = tqdm(total=epochs)\n",
    "    alpha = 1e-2\n",
    "    \n",
    "    X = X_full[0:500]\n",
    "    y = y_full[0:500]\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        prediction = model.forward(X=X)\n",
    "        loss_value = loss_fn.forward(y=y, y_pred=prediction)\n",
    "        accuracy = np.mean(accuracy_score(y, prediction))\n",
    "        \n",
    "        loss_history.append(loss_value)\n",
    "        accuracy_history.append(accuracy)\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({'loss': loss_value, 'accuracy': accuracy})\n",
    "        \n",
    "        model = backprop(X, y, prediction, model, loss_fn, alpha)\n",
    "    \n",
    "    pbar.close()\n",
    "    return loss_history, accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.24s/it, loss=1.15e+3, accuracy=0.826]\n"
     ]
    }
   ],
   "source": [
    "obj_fn = loss()\n",
    "model = Perceptron()\n",
    "loss_history, accuracy_history = train_loop(x_train_row, y_train, model, obj_fn, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1151.2925464970251, 1147.1047344703882, 1146.0845302222087, 1145.8301114206608, 1145.7604367884326]\n",
      "[]\n",
      "[0.82, 0.8263999999999999, 0.8263999999999999, 0.8263999999999999, 0.8263999999999999]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(loss_history[0:5])\n",
    "print(loss_history[995:1000])\n",
    "print(accuracy_history[0:5])\n",
    "print(accuracy_history[995:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.linear2.theta[0:].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0, 1, 2], [0, 1, 0]])\n",
    "mask = np.all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
